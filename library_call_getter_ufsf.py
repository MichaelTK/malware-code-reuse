import os
import pickle
import pandas as pd
import zipfile
import sys
import javalang
from grakel.kernels import WeisfeilerLehman, VertexHistogram
from grakel import Graph
from javalang.ast import Node
from tree import ASTNode, BlockNode
import string
import random
import re
from collections import Counter

PAIRS_PATH = "/home/k1462425/Documents/Research/malware-code-reuse-scripts/SourcererCC-artifact/sourc_results/results.txt"
DICTIONARIES_PATH = "/home/k1462425/Documents/Research/malware-code-reuse-scripts/SourcererCC-artifact/sourc_results/"
BLACKLIST_PATH = "/home/k1462425/Documents/Research/malware-code-reuse-scripts/uninteresting_library_list.txt"
# DATASET_PATH = "/media/k1462425/BackupsDrive/ufsf_java_repos_flat/ufsf_java_repos_flat/"
DATASET_PATH = "/home/k1462425/Documents/Research/malware-code-reuse-scripts/ufsf_java_repos_flat/ufsf_java_repos_flat/"

GLOBAL_FAILED = 0
SUCCESS = 0

def listdir_fullpath(d):
    return [os.path.join(d, f) for f in os.listdir(d)]

def main():
    global GLOBAL_FAILED
    global SUCCESS
    file_block_stats_path = DICTIONARIES_PATH+"file_block_stats/"
    all_lines = []
    files = listdir_fullpath(file_block_stats_path)
    for file in files:
        print(file)
        with open(file,'r',encoding='latin1') as fp:
            contents = fp.read()
            contents_split = contents.split("\n")
            for line in contents_split:
                if len(line) != 0:
                    all_lines.append(line)

    blockids_filepaths = get_blockids_filepaths(all_lines)
    blockids_frequencies = get_blockids_frequencies()
    blockids_locations = get_blockids_locations(blockids_frequencies,blockids_filepaths)

    projectids_blockids = get_projectids_blockids(all_lines)
    blockids_cloneblockids_similarities = pd.read_pickle(DICTIONARIES_PATH+'blockids_cloneblockids_similarities.pkl')

    blockids_cloneblockids_similarities_filtered = filter_blockids_cloneblockids_similarities(blockids_cloneblockids_similarities,blockids_locations,blockids_filepaths)
    if os.path.exists(DICTIONARIES_PATH+'blockids_cloneblockids_similarities_filtered_java.pkl'):
        os.remove(DICTIONARIES_PATH+'blockids_cloneblockids_similarities_filtered_java.pkl')
    with open(DICTIONARIES_PATH+'blockids_cloneblockids_similarities_filtered_java.pkl', 'wb') as handle:
        pickle.dump(blockids_cloneblockids_similarities_filtered, handle, protocol=pickle.HIGHEST_PROTOCOL)
    blockids_cloneblockids_similarities_filtered = pd.read_pickle(DICTIONARIES_PATH+'blockids_cloneblockids_similarities_filtered_java.pkl')
    sys.exit(0)
    clone_or_sibling_analysis(blockids_cloneblockids_similarities_filtered,blockids_filepaths,blockids_locations)
    sys.exit(0)

    if not os.path.exists(DICTIONARIES_PATH+'apicalls_freqs.pkl'):
        all_apicalls_freqs = get_apicalls_freqs_all(blockids_filepaths,blockids_locations,projectids_blockids)
        del all_apicalls_freqs[None]
        del all_apicalls_freqs['']
        # print(all_apicalls_freqs)
        most_common_apicalls = dict(Counter(all_apicalls_freqs).most_common(100))
        print(most_common_apicalls)
        print("Number of unique apicalls: "+str(len(all_apicalls_freqs)))
        print("Saving to pickle...")
        with open(DICTIONARIES_PATH+'apicalls_freqs.pkl', 'wb') as handle:
            pickle.dump(all_apicalls_freqs, handle, protocol=pickle.HIGHEST_PROTOCOL)
        print("Saved to: "+DICTIONARIES_PATH+'apicalls_freqs.pkl')
    else:
        with open(DICTIONARIES_PATH+'apicalls_freqs.pkl', 'rb') as handle:
            all_apicalls_freqs = pickle.load(handle)
        most_common_apicalls = dict(Counter(all_apicalls_freqs).most_common(100))
        print(most_common_apicalls)
        print("Number of unique apicalls: "+str(len(all_apicalls_freqs)))
        to_remove = []
        for key in all_apicalls_freqs.keys():
            if key[0].islower():
                to_remove.append(key)

        for key in to_remove:
            del all_apicalls_freqs[key]

        most_common_apicalls = dict(Counter(all_apicalls_freqs).most_common(400))
        print(most_common_apicalls)
        print("-----------------------------------------")
        prefixes_and_incidences_all = get_most_common_prefixes(blockids_cloneblockids_similarities_filtered,blockids_filepaths,blockids_locations,projectids_blockids)
        blacklist = read_blacklist()
        prefixes_to_remove = []
        for prefix in prefixes_and_incidences_all:
            if prefix in blacklist:
                prefixes_to_remove.append(prefix)
        for prefix in prefixes_to_remove:
            del prefixes_and_incidences_all[prefix]

        del prefixes_and_incidences_all[None]
        # del prefixes_and_incidences_all['']
        most_common_apicalls = dict(Counter(prefixes_and_incidences_all).most_common(300))
        print(most_common_apicalls)
        to_remove = []
        for key in prefixes_and_incidences_all.keys():
            if key[0].islower():
                to_remove.append(key)

        for key in to_remove:
            del prefixes_and_incidences_all[key]
        print("-------------------------------------")
        most_common_apicalls = dict(Counter(prefixes_and_incidences_all).most_common(300))
        print(most_common_apicalls)

def clone_or_sibling_analysis(blockids_cloneblockids_similarities_filtered,blockids_filepaths,blockids_locations):
    for triad in blockids_cloneblockids_similarities_filtered:
        if triad[2] > 0.87:
            blockid = triad[0]
            cloneblockid = triad[1]
            path1 = blockids_filepaths[blockid]
            dir1 = path1.split("/")[-2]
            file1 = path1.split("/")[-1][:-1]
            path1 = DATASET_PATH+dir1+"/"+file1

            path2 = blockids_filepaths[cloneblockid]
            dir2 = path2.split("/")[-2]
            file2 = path2.split("/")[-1][:-1]
            path2 = DATASET_PATH+dir2+"/"+file2
            blockid_code = get_code(path1,blockids_locations[blockid][1])
            cloneblockid_code = get_code(path2,blockids_locations[cloneblockid][1])
            if cloneblockid_code is not None and blockid_code is not None:
                if is_sibling(blockid_code,cloneblockid_code):
                    print("SIBLINGS:")
                    print(blockid_code)
                    print("----------------------------------")
                    print(cloneblockid_code)
                else:
                    print("CLONES:")
                    print(blockid_code)
                    print("----------------------------------")
                    print(cloneblockid_code)
            print("++++++++++++++++++++++++++++++++++")
            print("++++++++++++++++++++++++++++++++++")
            print("++++++++++++++++++++++++++++++++++")

def is_sibling(code1,code2):
    code1_lines = code1.split("\n")
    code1_returnline = ""
    for x in range(len(code1_lines)):
        if "return" in code1_lines[x]:
            code1_returnline = code1_lines[x]
    code1_returnline = code1_returnline.rstrip()

    code2_lines = code2.split("\n")
    code2_returnline = ""
    for x in range(len(code2_lines)):
        if "return" in code2_lines[x]:
            code2_returnline = code2_lines[x]
    code2_returnline = code2_returnline.rstrip()

    if code1_returnline == code2_returnline:
        return False
    return True


def get_most_common_prefixes(blockids_cloneblockids_similarities_filtered,blockids_filepaths,blockids_locations,projectids_blockids):
    prefixes_and_incidences = {}
    prefixes_and_incidences_all = {}
    blockids_to_process = []
    for triad in blockids_cloneblockids_similarities_filtered:
        if triad[2] > 0.87:
            blockids_to_process.append(triad[0])

    print("Number of blocks to get through: "+str(len(blockids_to_process)))
    projectids_prefixes = {}
    blockids_projectids = get_blockids_projectids(projectids_blockids)
    count = 0
    prefixes_and_projectincidences = {}
    prefixes_and_projectids = {}
    for blockid in blockids_to_process:
        prefixes_and_incidences = get_apicalls_freqs(blockids_filepaths,blockid,blockids_locations)
        projectids_prefixes[blockids_projectids[blockid]] = set([])
        for prefix in prefixes_and_incidences:
            projectids_prefixes[blockids_projectids[blockid]].add(prefix)
            if prefix not in prefixes_and_projectids.keys():
                prefixes_and_projectids[prefix] = set([])
            else:
                prefixes_and_projectids[prefix].add(blockids_projectids[blockid])

        # for prefix in prefixes_and_incidences:
        #     prefixes_and_incidences[prefix] = 1
        # for apicall in prefixes_and_incidences:
        #     if apicall not in prefixes_and_incidences_all.keys():
        #         prefixes_and_incidences_all[apicall] = prefixes_and_incidences[apicall]
        #     else:
        #         prefixes_and_incidences_all[apicall] = prefixes_and_incidences_all[apicall] + prefixes_and_incidences[apicall]

        count += 1
        if count % 10000 == 0:
            print(str(count)+"/"+str(len(blockids_to_process)))
            # return apicalls_freqs_all
    for prefix in prefixes_and_projectids:
        prefixes_and_projectincidences[prefix] = len(prefixes_and_projectids[prefix])


    return prefixes_and_projectincidences

def get_blockids_projectids(projectids_blockids):
    blockids_projectids = {}
    for projectid in projectids_blockids:
        for blockid in projectids_blockids[projectid]:
            blockids_projectids[blockid] = projectid
    return blockids_projectids

def filter_blockids_cloneblockids_similarities(blockids_cloneblockids_similarities,blockids_locations,blockids_filepaths):
    blacklist = read_blacklist()
    print("Filtering.")
    to_remove_triads = []
    for x in range(len(blockids_cloneblockids_similarities)):
        triad = blockids_cloneblockids_similarities[x]
        if is_rejectable(triad,blacklist,blockids_locations,blockids_filepaths):
            to_remove_triads.append(triad)
        if x % 1000 == 0:
            print(str(x)+"/"+str(len(blockids_cloneblockids_similarities)))

    print("To Remove triads: "+str(len(to_remove_triads)))
    count = 0
    for triad in to_remove_triads:
        blockids_cloneblockids_similarities.remove(triad)
        count += 1
        if count % 1000 == 0:
            print(str(count)+"/"+str(len(to_remove_triads)))

    print("Removed triads: "+str(len(to_remove_triads)))
    return blockids_cloneblockids_similarities

def is_rejectable(triad,blacklist,blockids_locations,blockids_filepaths):
    tokens_of_blockid = []
    tokens_of_cloneblockid = []
    blockid = triad[0]
    cloneblockid = triad[1]
    if is_rejectable_blockid(blockid,blacklist,blockids_locations,blockids_filepaths) or is_rejectable_blockid(cloneblockid,blacklist,blockids_locations,blockids_filepaths):
        return True
    return False

def is_rejectable_blockid(blockid,blacklist,blockids_locations,blockids_filepaths):
    path1 = blockids_filepaths[blockid]
    dir1 = path1.split("/")[-2]
    file1 = path1.split("/")[-1][:-1]
    path1 = DATASET_PATH+dir1+"/"+file1

    code = get_code(path1,blockids_locations[blockid][1])
    tokens_of_blockid = get_ast(code)
    for token in tokens_of_blockid:
        if token not in blacklist:
            return False
    return True

def read_blacklist():
    blacklist = []
    contents = ""
    with open(BLACKLIST_PATH,'r') as fp:
        contents = fp.read()
    lines = contents.split("\n")
    for x in range(len(lines)):
        lines[x] = lines[x].rstrip()
        blacklist.append(lines[x])
    return blacklist


def get_code(path,line_locs):
    lines = []
    line = ""
    try:
        with open(path,'r') as fp:
            try:
                line = fp.readline()
                lines.append(line)
                while line:
                    line = fp.readline()
                    lines.append(line)
            except Exception as e:
                return None
    except Exception as e:
        return None

    lines_pertaining = lines[int(line_locs[0])-1:int(line_locs[1])]
    # code = "public class main {\n"
    # code = code + "".join(lines_pertaining)
    # code = code + "\n}"
    code = "".join(lines_pertaining) + "}"
    return code

def get_projectids_blockids(all_lines):
    projectids_blockids = {}
    for line in all_lines:
        linesplit = line.split(",")
        project_id = linesplit[0][1:]     #get the id minus the 'b' or 'f' prefix
        firstcharacter = linesplit[0][0]
        if firstcharacter == 'f':
            if project_id not in projectids_blockids:
                projectids_blockids[project_id] = []
        if firstcharacter == 'b':
            block_id = linesplit[1]
            projectids_blockids[project_id].append(block_id)
    return projectids_blockids

def get_blockids_locations(blockids_frequencies,blockids_filepaths):
    files = listdir_fullpath(DICTIONARIES_PATH+"blocks_stats")
    blockids_locations = {}
    all_lines = []
    for file in files:
        with open(file,'r') as fp:
            content = fp.read()
            lines = content.split("\n")
            for line in lines:
                if len(line) > 0:
                    all_lines.append(line)
    blockids_ranges = {}
    for line in all_lines:
        if len(line) > 5:
            linesplit = line.split(",")
            #print(linesplit)
            blockids_ranges[linesplit[1]] = (linesplit[-2],linesplit[-1])
    for blockid in blockids_filepaths:
        blockids_locations[blockid] = (blockids_filepaths[blockid],blockids_ranges[blockid])
    return blockids_locations

def get_blockids_frequencies():
    blockids_frequencies = {}
    lines = []
    with open(PAIRS_PATH,'r') as fp:
        lines = fp.read()
        lines = lines.split("\n")
    for line in lines:
        if len(line) > 0:
            linesplit = line.split(",")
            hostid = linesplit[1]
            cloneid = linesplit[3]
            if linesplit[0] != linesplit[2]:
                blockids_frequencies[hostid] = 0
                blockids_frequencies[cloneid] = 0
    for line in lines:
        if len(line) > 0:
            linesplit = line.split(",")
            hostid = linesplit[1]
            cloneid = linesplit[3]
            if linesplit[0] != linesplit[2]:
                blockids_frequencies[hostid] = blockids_frequencies[hostid] + 1
                blockids_frequencies[cloneid] = blockids_frequencies[cloneid] + 1
    return blockids_frequencies

def get_blockids_filepaths(all_lines):
    blockids_filepaths = {}
    fileid = 'ayooooooooooo'
    filepath = ''
    for line in all_lines:
        linesplit = line.split(",")
        firstcharacter = linesplit[0][0]
        if firstcharacter == 'f':
            fileid = linesplit[1]
            filepath = linesplit[2]
        if firstcharacter == 'b':
            blockid = linesplit[1]
            if blockid.endswith(fileid):
                blockids_filepaths[blockid] = filepath
    return blockids_filepaths

def get_sequence_methodinvocs(node, parent, sequence, child_of_methodinvoc):
    token = get_token(node, parent)
    children = get_children(node)

    token, children = get_token(node, parent), get_children(node)
    if isinstance(node,javalang.tree.MethodInvocation):
        child_of_methodinvoc = True
    if child_of_methodinvoc:
        # print("-------")
        # print(node.__class__.__name__)
        # print(token)
        if isinstance(node,javalang.tree.MethodInvocation):
            # print(node)
            # print(node.qualifier)
            # print("test")
            # print(node.member)
            sequence.append(node.qualifier)

        # print("-------")
        # sequence.append(token)

    # if isinstance(node,javalang.tree.MethodInvocation):
    #     get_sequence_methodinvocs(children[0],node,sequence,child_of_methodinvoc)

    # else:
    for child in children:
        # print(child.__class__.__name__)
        get_sequence_methodinvocs(child, node, sequence, child_of_methodinvoc)

    # if token in ['ForStatement', 'WhileStatement', 'DoStatement','SwitchStatement', 'IfStatement']:
    #     sequence.append('End')
    return sequence

def get_ast(code):
    exceptionCount = 0
    members = []
    edges = {}
    hashes_and_tokens = {}
    try:
        tokens = list(javalang.tokenizer.tokenize(code))
        parser = javalang.parser.Parser(tokens)
        tree = parser.parse_member_declaration()
        #functions_apicalls[funcfile+":"+subfuncs[2][x]] = []
        # print(tree)

        members = get_sequence_methodinvocs(tree,None,members,False)
        # print(members)
        # print("Members")
        # print(members)

    except Exception as e:
        # print(e)
        exceptionCount += 1
        return members

    return members

def get_token(node,parent):
    token = ''
    # if isinstance(node,javalang.tree.MethodDeclaration):
    #     print("METHOD DECLARATION!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    if isinstance(node, str):
        token = node
    elif isinstance(node, set):
        token = 'Modifier'#node.pop()
    elif isinstance(node, Node):
        token = node.__class__.__name__
        # token = ""
        # if "MemberReference" in token:
        #     print("MEMBER REFERENCE:")
        #     children = get_children(node)
        #     print(children)
        # if "MethodInvocation" in token:
        #     print("METHOD INVOCATION:")
        #     children = get_children(node)
        #     print(children)

    return token

def get_children(root):
    if isinstance(root, Node):
        children = root.children
    elif isinstance(root, set):
        children = list(root)
    else:
        children = []

    def expand(nested_list):
        for item in nested_list:
            if isinstance(item, list):
                for sub_item in expand(item):
                    yield sub_item
            elif item:
                yield item

    return list(expand(children))

def get_apicalls_freqs(blockids_filepaths,blockid,blockids_locations):
    apicalls_freqs = {}
    path1 = blockids_filepaths[blockid]
    dir1 = path1.split("/")[-2]
    file1 = path1.split("/")[-1][:-1]
    path1 = DATASET_PATH+dir1+"/"+file1

    # print(path1)
    # print(get_code(path1,blockids_locations[blockid][1]))
    the_ast = get_ast(get_code(path1,blockids_locations[blockid][1]))
    # the_ast = get_libraries_called(get_code(path1,blockids_locations[blockid][1]))
    # print(the_ast)
    if the_ast is not None:
        for node in the_ast:
            apicalls_freqs[node] = 0
        for node in the_ast:
            apicalls_freqs[node] = apicalls_freqs[node] + 1
    # print(apicalls_freqs)
    return apicalls_freqs

def get_libraries_called(code):
    libraries = []
    # prog = re.compile('ab*')
    # prog = re.compile(r'(\.[\s\n\r]*[\w]+)[\s\n\r]*(?=\(.*\))')
    prog = re.compile(r'([\s\n\r]*[\w]+)(\.[\s\n\r]*[\w]+)[\s\n\r]*(?=\(.*\))')
    result = prog.findall(code)
    print(result)
    result = list(result)
    if result is not None and len(result) > 0:
        for x in range(len(result)):
            result[x] = list(result[x])
            print("BEFORE PROCESS")
            print(result[x][0])
            interm1 = result[x][0].rstrip('\n')
            interm2 = interm1.rstrip(' ')
            interm3 = interm2.rstrip('\t')
            result[x][0] = interm3
            print("AFTER PROCESS")
            print(interm3)
            print(result[x][0])
    print(code)
    print("RESULT")
    print(result)
    print("END")
    return None


def get_apicalls_freqs_all(blockids_filepaths,blockids_locations,projectids_blockids):
    apicalls_freqs_all = {}
    num = 0
    for projectid in projectids_blockids:
        for blockid in projectids_blockids[projectid]:
            num += 1
    print("Number of blocks to get through: "+str(num))

    count = 0
    for projectid in projectids_blockids:
        for blockid in projectids_blockids[projectid]:
            apicalls_freqs = get_apicalls_freqs(blockids_filepaths,blockid,blockids_locations)
            # print(apicalls_freqs)
            for apicall in apicalls_freqs:
                if apicall not in apicalls_freqs_all.keys():
                    apicalls_freqs_all[apicall] = apicalls_freqs[apicall]
                else:
                    apicalls_freqs_all[apicall] = apicalls_freqs_all[apicall] + apicalls_freqs[apicall]

            count += 1
            if count % 10000 == 0:
                print(str(count)+"/"+str(num))
                # return apicalls_freqs_all

    return apicalls_freqs_all

main()
